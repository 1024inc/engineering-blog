[ { "title": "Mocking requests to third party services", "url": "/posts/mocking-requests-to-third-party-services/", "categories": "", "tags": "", "date": "2022-08-09 19:00:00 -0500", "snippet": "Third party services are frequently used to extend the functionality of our product/service, especially in cases where what is needed grows beyond the limits of our industry or purpose. Once an integration is set up and running, naturally this must be included in our automation tests, right? (right?)It is a widely accepted practice to always mock requests made to third party services while testing, integration tests included. The reasoning behind this lies in 2 main areas: We don’t control the response we get. This may lead to flaky tests, our testing suite failing because of service unavailability etc. The negative impact is even greater when a CI/CD process is used to deploy to our production and staging environments. Not to mention hotfixes… Tests may take a while, since a connection is in the middle of it. If our suite consists of hundreds or thousands of tests, this may add up to a horrible amount of time to complete the suite.So what are the best ways to mock those requests in our automated tests?Sample caseLet’s say that in our product, we deal with international customers who pay in different currencies and we want to convert everything to let’s say USD. To do so we can use the OpenExchange API. Here is a sample code to implement this:import requestsclass ExchangeRatesClient: def __init__(self): self.base_url = &quot;https://open.er-api.com/v6/latest/&quot; def get_exchange_rates(self, currency_code): url = self.base_url + currency_code response = requests.get(url) response.raise_for_status() return response.json()Good ol’ monkeypatchMonkeypatch is a fixture from pytest which allows us to easily patch attributes. In this case the get() function of requests.Example:class MockResponse: def __init__(self, json_data, status_code): self.json_data = json_data self.status_code = status_code def json(self) return self.json def raise_for_status(self) returnclass TestExchangeRatesClient: def test_get_exchange_rates(self, monkeypatch): #assign exchange_rates_client = ExchangeRatesClient() expected_value = { &quot;result&quot;: &quot;success&quot;, &quot;base_code&quot;: &quot;USD&quot;, &quot;rates&quot;: { &quot;USD&quot;: 1, &quot;CAD&quot;: 1.26, &quot;CHF&quot;: 0.941, &quot;EUR&quot;: 0.923, &quot;GBP&quot;: 0.765, &quot;JPY&quot;: 125.9, }, } mock_requests = Mock( return_value = MockResponse(json_data = expected_value, status_code = 200) ) monkeypatch.setattr(requests, &quot;get&quot;, mock_requests) #act result = exchange_rates_client.get_exchange_rates(currency_code=&quot;USD&quot;) #assert assert result == expected_valueHow it works:When requesting data, we get a Response object so we have to mock its behaviour. This is what the class MockResponse is doing. This class may change depending on how we use the response object. Eg. we may need to add a text attribute, or add logic to the raise_for_error() to mock its behaviour and raise an HTTPError in case of an invalid status_code (4xx-5xx)PROS: Doesn’t depend on 3rd party libraries Flexibility on implementing exotic cases when mockingCONS: In real life examples, the response object can be very complex (headers, huge reponses, cookies etc) which can make the MockResponse class a hairy mess Monkeypatching has a global effect. If there were more requests we had to use side_effect and things could break. If instead of requests.get we use requests.Session().get(), then monkeypatching goes bust.Requests-mockFrom the solution above we see that there is a lot of logic inside the MockResponse which isn’t always pleasant and we may introduce more bugs. And it feels a little too custom of a solution for such a generic problem to solve. So yeah… you guessed it. There is a library for that. One of the mostly used libraries in the python world is requests-mockExampledef test_get_exchange_rates_with_requests_mock(self): # assign exchange_rates_client = ExchangeRatesClient() expected_value = { &quot;result&quot;: &quot;success&quot;, &quot;base_code&quot;: &quot;USD&quot;, &quot;rates&quot;: { &quot;USD&quot;: 1, &quot;CAD&quot;: 1.26, &quot;CHF&quot;: 0.941, &quot;EUR&quot;: 0.923, &quot;GBP&quot;: 0.765, &quot;JPY&quot;: 125.9, }, } # act with requests_mock.Mocker() as m: m.get(&quot;https://open.er-api.com/v6/latest/USD&quot;, json=expected_value) result = exchange_rates_client.get_exchange_rates(&quot;USD&quot;) assert result == expected_valueHow it worksWithin the context manager, every request is being mocked by declaring it using the method and url. Regex can be used for more dynamic matching. If a request is not matched, then requests_mock will throw an exception and the test will fail, thus preventing the call to an external endpoint. Here, there are arguments as well to specify status_code, json, text etc depending on the desired response.PROS Easy to use Flexibility Less code Mock response objects have the desired behaviour by defaultCONS You need to explicitly take care of every request in terms of expected values Hand written expected valuesVCR.pyStorming from Ruby’s VCR library, VCR.py brings all the 80s nostalgia that we secretly crave for is a neat and powerful library that takes away most of the pain. What it does is that it records every http request done inside a test and “writes” them in a (by default .yaml) file. This file is then reused every time a request needs to be mocked. If there are more than one requests, then it records them all and are exposed in the cassette.responses list.Exampledef test_get_exchange_rates_with_vcr(self): # assign exchange_rates_client = ExchangeRatesClient() # act with vcr.use_cassette( &quot;exchange_rates.yaml&quot;, serializer=&quot;yaml&quot;, decode_compressed_response=True ) as cassette: result = exchange_rates_client.get_exchange_rates(&quot;USD&quot;) # assert assert result == json.loads(cassette.responses[0][&quot;body&quot;][&quot;string&quot;])How it worksThis library is very flexible and can be configured in many different ways.Decorator vs context managerFirst it can be used as a decorator to mock all requests within a test, or as a context manager to mock requests in a specific area inside the test, allowing to have different VCR objects per request with different configurations. The vcr.use_cassette() can be used to specify the file to write and/or the path of that file. Ex. with vcr.use_cassette(“path/to/folder/exchange_rates.yaml”)Record modesonce (default)When a request is about to happen, it checks if the file exists. If not, it makes an actual request, and writes it into the file. IF the file exists already, it uses that file instead of the actual request. If the file exists but the request is different than the one that it is recorded in, then it raises an error. This is the most used record mode. Usually we make a real request (with api_keys etc) and then we remove the sensitive code (we can also filter headers, query_parameters as described here)If something goes wrong, then we can simply delete the .yaml file and run the test again.noneNever make a real http request. It is mostly used when we want to be absolutely sure that an http endpoint is never called because that endpoint is sensitive.allAlways make an http request. This mode is not for mocking but when we want to override an existing cassette without deleting the file or when we want to simply log requests (rare)new_episodesLike the once mode, but in case there is a file with a similar request, it overrides it instead of raising an exceptionSample ConfigurationA very common blocker when first using this library is to create a generic configuration that all subsequent tests can easily use. Here is a personal favourite: a double wrapped func. Config file:# here more params can be addeddef vcr_cassette(cassette_path): def inner(func): @wraps(func) def conf_vcr(*args, **kwargs): # default config vcr = VCR( record_mode=record_mode.RecordMode.ONCE, decode_compressed_response=True, serializer=&#39;yaml&#39;, cassette_library_dir=os.path.join( os.path.dirname(os.path.realpath(__file__)) + &#39;/cassettes/&#39; ), ) with vcr.use_cassette(cassette_path): return func(*args, **kwargs) return conf_vcr return innerUsage:@vcr_cassette(&quot;exchange_rates.yaml&quot;)def test_get_exchange_rates_with_vcr(self): # assign exchange_rates_client = ExchangeRatesClient() # act result = exchange_rates_client.get_exchange_rates(&quot;USD&quot;) # assert assert result == json.loads(cassette.responses[0][&quot;body&quot;][&quot;string&quot;])PROS Easy to use Flexibility Stores real responses and is easy to record the complex ones that would be a nightmare to mock them manually Ability to view those responses Ability to hide/not record sensitive information like tokens/api keys etc Easily record multiple calls within a test, which in normal cases would be hard to mock.CONS Every time there is a change in a request, that means that a response needs to be generated. But what happens if that response was time sensitive and changes in time? (Trick is to - manually tweak the request). A live request is needed if the record mode is set to ONCE. Sometimes this is impossible. Configuration can be daunting at firstConclusionSo there you have it. When dealing with third parties there is a range of strategies that can fit to a variety of cases. Here at Beyond we prefer the feature rich and production-ready solution of the VCR library, since we are doing a heavy use of external requests. The other solutions proposed can also be an ideal approach, especially for simpler cases." }, { "title": "Tools to backfill large PostgreSQL tables (part 1)", "url": "/posts/tools-to-backfill-large-postgresql-tables-pt1/", "categories": "", "tags": "", "date": "2022-05-31 19:00:00 -0500", "snippet": "At Beyond we are mainly using PostgreSQL databases for our services, consisting of over a hundred tables. With some of the largest ones we’ve already had a few close calls as they were reaching the maximum supported 32TB table size - but that’s a story for another day. Backfilling tables that large is not a trivial task, assuming we want to perform it safely, and within a reasonable timeframe. In this post, we are going to outline a few methods and tools similar to what we have successfully used to make this process scalable, and a little less painful.What’s backfilling and why can it be a problem?Backfilling simply means modifying or adding new data to existing database records, i.e. running UPDATE statements, but with an emphasis on performing it on all or most of the records in a table.When would it be needed? We want to modify a column’s value to fix faulty data We have to add a new field, i.e. insert a new column to the table, with either a default value or with data computed by arbitrary business logic.In any case, the main issue is that if we want to perform a backfill on a seriously large table, it just simply takes a very long time. And by that I mean if we just naively issue an UPDATE table SET field=value WHERE id=n for each and every row, it will finish in weeks, months, or even years, depending on the use case’s context. In a specific case, we had to update a 22TB table with hundreds of billions of rows where the estimated time to completion was over 2 years.With tables of this size, just creating a copy of the whole table and doing the update on it to avoid certain problems is not always a viable option, so we’ll focus on the use case where we really want to update the live table.The first challenge is to complete this process as quickly as possible, naturally. The second one is to accept that it won’t be quick enough, and come up with tools that make this task more controlled and manageable, while making sure our application can still operate on the table without major hiccups.What can we do?Our fictional scenario will be performed on a table named users. We’ll act like we have billions of users in our system. We want to backfill this table, inserting values into our newly created reversed_last_name column where we want to store our users’ last name, but, wait for it: reversed. And we want to do this because of, well, reasons. We will also pretend this is something that needs some calculations beforehand in a script and we couldn’t possibly do the update with just a snappy SQL expression (you know, like REVERSE()).Let’s perform the update in batchesUpdating rows one by one puts a massive overhead on the process, and is the primary culprit for slowness. The solution seems simple enough: use as few individual UPDATE statements as possible. To do this, we want to write our data migration script so that it will output SQL which uses PostgreSQL’s CASE expression:UPDATE users SET reversed_last_name = ( CASE WHEN id = 1 THEN &#39;htulB&#39; WHEN id = 2 THEN &#39;nasemraP&#39; WHEN id = 3 THEN &#39;walboL&#39; [...] ELSE last_name END)WHERE id &amp;gt;= 1 AND id &amp;lt;= 500As you can see from the WHERE clause, we want to build update statements only for a subset of data. We might be tempted to build one huge UPDATE on all the rows, but there are a couple of issues with that. You’ll find that PostgreSQL puts an entire table lock on this huge table until the statement execution is completed, which unfortunately still won’t happen fast enough. Besides our application being denied write access to any rows, it would very likely cause a myriad of other issues. What works best is finding an equilibrium, and executing the updates in batches, balancing the number of rows affected in one batch, being aware that they will be locked while being updated, but processed and released from the lock in a reasonable amount of time.To help us compose these batch operations, we’ll create a simple iterator class that will receive a database connection, the name of the table we want to backfill, the desired batch size, and an optional start_batch indicator that will come in handy later, when we implement a pause/resume feature and parallel processing. The class retrieves the max id of the table, and will yield us id boundaries according to the batch size, with a begin_id and an end_id which will help us build our select queries and batched update statements.This is a simplified example and it assumes we have integer primary keys called id and we have a data set starting from id=1.import mathclass TableBatchIterator: def __init__(self, conn, table, batch_size, start_batch=1): self.batch_size = batch_size self.start_batch = start_batch self.max_id = self.table_max_id(conn, table) self.total_batches = math.ceil(self.max_id / batch_size) def __iter__(self): self.current_batch = self.start_batch return self def __next__(self): if self.current_batch &amp;gt; self.total_batches: raise StopIteration begin_id = (self.current_batch - 1) * self.batch_size + 1 end_id = min(self.current_batch * self.batch_size, self.max_id) self.current_batch += 1 return (begin_id, end_id) @staticmethod def table_max_id(conn, table): with self.conn.cursor() as cursor: cursor.execute(f&#39;SELECT max(id) FROM {table};&#39;) row = cursor.fetchone() return row[0]To build the update statements shown above, we’ll also need something that takes the begin and end id values, the field name, and the new value. We’ll use a simple to use class for this.The BatchUpdateBuilder class exposes two public methods: update(), which will be responsible for accumulating all the new values we want to persist for a given id and column name, and build_sql(), which will return the corresponding UPDATE SQL statement string with the CASE/WHEN expressions built from the values stored by update(). It will also append a WHERE clause to the statement to narrow down the scope to rows concerned in the given batch.import jsonclass BatchUpdateBuilder: def __init__(self, table, begin_id, end_id): self.table = table self.begin_id = begin_id self.end_id = end_id self.updates = {} def update(self, _id, field, new_value): field_updates = self.updates.setdefault(field, {}) field_updates[_id] = new_value def build_sql(self, begin_id, end_id): if not self.updates: return None sql = ( f&#39;UPDATE {self.table}\\\\n&#39; f&#39;SET\\\\n{self._build_cases()}\\\\n&#39; f&#39;WHERE {self._build_where(begin_id, end_id)}&#39; ) return sql def _build_cases(self): cases = [] for field, field_updates in self.updates.items(): cases.append(self._build_field_case(field, field_updates)) return &#39;,\\\\n&#39;.join(cases) def _build_field_case(self, field, field_updates): cases = [] for _id, new_value in field_updates.items(): cases.append(f&#39;WHEN id = {_id} THEN {self._to_sql_value(new_value)}&#39;) cases = &#39;\\\\n &#39;.join(cases) return ( f&#39; {field} = (\\\\n&#39; &#39; CASE\\\\n&#39; f&#39; {cases}\\\\n&#39; f&#39; ELSE {field}\\\\n&#39; &#39; END\\\\n&#39; &#39; )&#39; ) def _build_where(self): return f&#39;id &amp;gt;= {self.begin_id} AND id &amp;lt;= {self.end_id}&#39; @staticmethod def _to_sql_value(value): if type(value) in (dict, list): return f&#39;\\\\&#39;{json.dumps(value)}\\\\&#39;::jsonb&#39; elif type(value) is str: return f&#39;\\\\&#39;{value}\\\\&#39;&#39; elif value is None: return &#39;null&#39; else: return str(value)With these in place, we can do something like this, demonstrating with a Django example:from django.db import connectionfrom . import BatchUpdateBuilder, TableBatchIteratorBATCH_SIZE = 500TABLE_NAME = &#39;users&#39;table_batch_iterator = TableBatchIterator( conn=connection, table=TABLE_NAME, batch_size=BATCH_SIZE)cursor = connection.cursor()for boundaries in table_batch_iterator: begin_id, end_id = boundaries batch_update_builder = BatchUpdateBuilder(TABLE_NAME, begin_id, end_id) users = User.objects.select_for_update().filter(id__gte=begin_id, id__lte=end_id) for user in users: reversed_last_name = user.last_name[::-1] batch_update_builder.update(user.id, &#39;reversed_last_name&#39;, reversed_last_name) sql = batch_update_builder.build_sql() cursor.execute(sql)cursor.close()Pretty straightforward. We create an instance of the TableBatchIterator instrumented to perform the updates in batches of 500 (at most, actual batch size may vary if rows with certain id values are missing) on our users table, then iterate through it to build and execute a bunch of UPDATE statements generated by the BatchUpdateBuilder.Moving forwardIn the second part of this blog post we’ll be going further, adding a progress calculator to help us monitor the status of the process, and as a last step we will create a lightweight queue system that makes it possible to run the task in parallel processes while also allowing us to pause and resume the process on demand." }, { "title": "Empathy and Compassion in Communication (part 2)", "url": "/posts/empathy-and-compassion-in-communication-part-2/", "categories": "", "tags": "", "date": "2022-04-11 23:00:00 -0500", "snippet": "Effective engineers are strong problem solvers. Great engineers have also become inspiring leaders and master communicators. Whether you want to take your career to the next level, or simply aspire to round-up your skillset, leveling up your self-awareness and communication skills will open many doors on your personal and professional path. In a spirit of sharing, here are four lessons I have learned.This is a continuation of part 13. Resort to your problem-solving abilitiesTL;DRAnalyze problems in a systematic, pragmatic way, and don’t stop thereAssess whether you want to tackle the situation or notAsk yourself “What is it that I can do about it?”Use a language of gaps and possibilities rather than one of problemsPropose multiple solutions, as diverse as possibleHonestly list the pros/cons staying away from your own biasesEstablish a plan to bridge the gap and a way to measure progressFollow up regularlyAvoid resorting to problem solving when you engage with someone in an emotionally challenging place, unless they request it.As engineers and scientists, we have an innate curiosity and desire to figure out how systems work. By understanding how something works, we can come up with hypotheses on how certain changes affect its behavior, and subsequently empirically verify our predictions. Business and communication are no different and can be looked at under this same lens.Identifying a problem however, is just the first step toward speaking it out. As a young engineer, I often found myself stopping at that step and just communicating the problem once identified. That was a fundamental mistake. Despite noble intentions, we will often be perceived as problem makers, not problem solvers.Once we identify a problem (the “What”), the first thing we need to address is whether or not there is enough at stake to justify the cost of beginning to explore solutions and eventually solving it (the “If”). We subconsciously do this all the time, when we screen out information to focus on what matters. The same can be applied to problem solving. Not every single problem needs to be solved. Our bandwidth and willpower are limited, and we ought to prioritize and focus on what matters from a business, personal or relationships standpoint.We can start to reflect and prepare our communication. One of the most empowering question we can ask ourselves anytime we encounter a challenge is: “What is it that I can do about it?”. Put emphasis on the “I” and point both index fingers at yourself while asking this question. Sometimes it feels like things are out of our hands. But in truth, there is always something we can do about it. We always have a choice to talk and act in a candid fashion, or not to. Taking ownership of our part is an efficient way to start a positive dynamic with compassionate intentions, and will set us up for success when we engage in communication.If we decide to move forward, we then need to clearly articulate the “What” we identified in the previous step. Most often, a good approach is to describe the issue as a gap and quantifying it whenever possible. Expressing a gap is simply saying “Here we are. We want to get there. What can we do about it?” Speaking in terms of gaps is a language of possibilities and opportunities instead of a language of problems, concerns, blame, and exhortation. Here is an example that illustrates the contrast between the two approaches:Problem language: “I have some bad news. We are tracking behind our sales target.”Possibilities language: “It is January 31st and we are currently at $200K in sales for Q1. Our goal is to reach $900K by the end of Q1. So, we are currently tracking $100K behind. Let’s talk, what can we can do to bridge that gap?”Possibility lies in making a difference and creating value from a situation, without denying that certain issues exist. ¹ -Benjamin ZanderThe next step is challenging ourselves to express as many potential solutions as we can think of. It is important to keep our mind open, as we always tend to fall into our biases and convincing ourselves that “This is the only real way.” At this point, we really help resolve issues and become problem solvers. An efficient way to keep each other in check when exploring and comparing multiple options, is to pragmatically list the pros and cons for each of them.Once a plan is chosen to address the gap, we can figure out ways to measure progress as objectively as possible. Timelines and Gantt charts are often applicable here, and we can also decide to measure progress based on value output KPIs, which take into account key parts of the gap we are bridging. The trick here is to find the right balance where what is measure is not too generic and abstract and not too specific either.Finally, make a point to follow up regularly. Failing to do so is failing to promote healthy accountability, and somewhat nullifies all the work that was done to this point. We can share status updates, use information radiators such as digital and physical boards and foster a culture transparency, accountability and predictability.Problem solving and gap bridging are great tools to have in our bag, but they are not adapted to every situation. In fact they can be destructive and counterproductive when someone is emotionally struggling. In such instances we need to resort to simply expressing empathy and practicing compassion.4. Show empathy and practice compassionTL;DREmpathy and compassion are crucial at all levels of communication, especially in conflict resolution and emotional supportRefrain from using problem solving (3.)Put your opinions aside and listen (1.)Validate his/her perspectiveIf you can genuinely relate, express your feelingsAsk what he/she would do, and refrain from debatingSometime just being there in silence is enough, and sometime being compassionate is respecting the need of others to be aloneSometimes we find ourselves communicating with someone who is struggling emotionally, perhaps experiencing a difficult problem at work or going through a challenging time in their personal life. In these situations, avoid resorting to problem solving. When someone is overwhelmed by their feelings, we want to validate their feelings and support them emotionally, thereby giving them something to relate to and to hold onto.It is therefore important to refrain from diminishing how someone feels. Sugar-coating or trying to minimize the impact of the situation at stake can sound like this:“This is no big deal, don’t worry you will be alright”Here the message is:“I can’t relate to you. I have no idea what you are going through and I can’t feel your pain.”Similarly, we want to be very wary of patronizing:“If you think what happened to you is bad, let me tell you what I went through last year…”We should also refrain from resorting to our engineering approach of providing solutions when someone is frustrated, upset, sad, angry,… Instead, we can come down from our head to our heart and our senses, and give the gift of our support and our presence. Most often, that just mean sitting next to them and saying:“This sucks. I know how much of a big deal this is for you. I saw you do everything you could.”Show up for people in pain and don’t look away. If we want people to bring their whole selves including their unarmored, whole hearts —so that we can innovate, solve problems, and serve people— we have to be vigilant about creating a culture in which people feel safe, seen, heard, and respected.²-Bréné BrownWe can also resort to simple construction to show empathy, even when we are facing a conflictive situation³:“Are you feeling &amp;lt;guess their feeling&amp;gt;, because you need &amp;lt;guess their need&amp;gt;?”This can help us connect in a kind and compassionate way. It doesn’t matter whether we accurately identify the feeling or the need behind it, as long as we show a genuine intent to connect on that level.Dao 道Improving our communication and EQ is not as easy as reading a blog post. This territory seems completely limitless to me, made of a myriad of skills of all sizes from learning to say “Thank you!” to public speaking. Each one complements the others and, as we practice them, make us well rounded communicators. And so, if you wish to become a speaker, a leader or simply a better spouse, parent or colleague, prepare yourself for a lifelong adventure of learning and enjoy the ride! There is no end goal here, it is about the journey toward the ideal. Only by understanding that we can never reach it, can we get closer to it.Thank you for taking the time to read this article. I am grateful for your time and consideration. I will cherish the gift of feedback, and would appreciate if you could tell me in the comments: The one concept that most resonated with you Any suggestions you may have to improve the content or the deliveryThank you! 🙏1: Benjamin Zanders, Choosing Your World, Google ZeitGeist, 2011 ↩2: Bréné Brown, Dare to Lead ↩3: Marshall Rosenberg, Nonviolent Communication: A Language of Life ↩" }, { "title": "Empathy and Compassion in Communication (part 1)", "url": "/posts/empathy-and-compassion-in-communication-part-1/", "categories": "", "tags": "", "date": "2022-04-10 23:00:00 -0500", "snippet": "Effective engineers are strong problem solvers. Great engineers have also become inspiring leaders and master communicators. Whether you want to take your career to the next level, or simply aspire to round-up your skillset, leveling up your self-awareness and communication skills will open many doors on your personal and professional path. In a spirit of sharing, here are four lessons I have learned.Humans and computersThe story began when I was nine years old. Personal Computers were beginning to make their way into schools and libraries. I was privileged and fortunate enough to have one at home, and very lucky to find a friend who taught me the essentials of hardware and software. In those days you needed to know both. You would program the chip directly, there was no Garbage Collection and, in this case, a fancy 512 KB of memory to play with. Computer programming was a different animal altogether, and quite fun to me. It felt like a game, and still does to this day. And so, I followed a somewhat established path of math and science education to eventually land a job at playing my favorite game. Mission complete? Well, not quite.As time went by, I eventually realized that my need for connection with others wasn’t quite fulfilled through my studies or my work. It didn’t feel like I was helping and connecting with others in a direct and meaningful way. I was intrigued and curious about other business functions, especially product and marketing, which heavily rely on communication. “What’s so hard about it?”, I thought. I was in for quite a surprise. I could never have imagined, even in my wildest dreams, how subtle, complex and refined that new game can get.As I decide to undertake the journey and start a new business in Chile in 2002, I soon realize that the task at hand was daunting, not that of building our product, but that of building our product together. This adventure of collaboration altered the course of my journey. It crystallized into a realization that “Communicating with computers is far simpler than communicating with people”, or to put it in reassuring engineering language, “People are systems of immense complexity, and spoken languages, protocols of colossal intricacy.”So I began learning. I listened to the advice of peers and proven communicators and carefully watched them in action. I read books on effective communication, emotional intelligence, and team leadership and practiced one skill at a time before moving on to the next one. One of the most important steps I took was reaching out to teammates whom I had failed to listen to, understand and support effectively. I asked them what I could have done better, and I listened.Learning, to me, encompasses the purpose of life. It is playful in its essence and makes living about the journey rather than the destination.Four principles I try to practice along the way1. Listen, listen, listen… and watchTL;DRTry and listen with your ears, eyes and heart, not just with your headSpeak tentatively and create space for others to safely share their storiesWatch and listen to yourself as much as othersStay candid when it is hard to do so, that is when it matters the mostLeverage mirroring and other active listening techniquesExploring possibilities with teammates, friends and mentors is often a good way to start learning any skill. So I asked around.“In your opinion, what are the three most important skills in communication?”Nearly invariably, “Listening” was part of the answer. David Deal, whom I consider an expert craftsman in that field, and who happens to help me write these very lines, answered that question with “1. Listen, 2. Listen, 3. Listen.”What does it mean to listen, and how can we get better at it? I believe the answer greatly depends on our degrees of extroversion, and intuition. Listening is in part creating space and safety for others to participate in the exchange of information. The more extroverted we are in relation to others, the more we should be self-aware of our propensity to occupy that space and refrain from doing so. Listening means opening our mind to the ideas of others, and broadening our perspective by leveraging diversity of thoughts.“Listen with the intent to understand, not respond.” ¹ -Stephen CoveyThe more intuitive we are, the more we tend to solve puzzles and search for information inside instead of outside. And so we listen to our own internal voice using our mind rather than to the voice of others, using our ears. If you are intuitive, which can be considered a trait for many engineers, try to tame your inside voice and make the effort to clearly listen to others. If you are ever in doubt, you can always use paraphrasing and other active listening techniques. Many experiments have proven that the exact intended meaning of a message, is nearly never fully understood. And so, we can always pause and resort to constructions such as:“This is what I heard you say: &amp;lt;fill in&amp;gt;. I understand what you mean is &amp;lt;extract meaning&amp;gt;. Is that right?”Finally, being in receiving mode means listening for a message. That message is not solely composed of words. If we are in an oral conversation, intonation becomes a crucial part of the meaning. Even more importantly, body language can reveal an undercurrent that is most often unintentional. It is therefore critical to learn to look and become attuned with one’s emotion inside, and others’ outside, as they tell us a raw, unfiltered story about ourselves, our teammates and about the dynamics in a meeting room.2. Stick to observations, avoid judgements and evaluationsTL;DRSlow down, recognize when you are telling yourself “villains or victims” storiesSearch for explanations that presuppose of positive intentQuestion yourself to grow. You are the only one that you can changeUse a pragmatic language of observations devoid of evaluationsOne of the major hurdles we create for ourselves is making suppositions that, in the blink of an eye become assumptions, increasing and confirming our biases while dictating our emotional response, and subsequently our behavior. These stories are often unconsciously designed to validate our pre-existing biases and to explain the world in a way that doesn’t require questioning ourselves, thereby preventing us from learning and growing.Our prefrontal cortex (part of the new hardware that evolution has provided us) is in a perpetual quest of understanding and predicting the world around us. It does so very fast, and generally assumes a worst case scenario. This evolution design is at the root of “fight, flight, or freeze” and other primitive behaviors that helped our ancestors escape predators. This kind of responses, however, are counterproductive in our modern world, where teamwork and collaboration are essential to success.Validating assumptions that support the shortest and the easiest way to an explanation, prevents us from questioning ourselves. This can result in finger pointing supported by our invented villain and victim stories. It prevents us as a group from understanding a situation objectively. On the other hand, we can decide to ask ourselves questions such as “Where could I be mistaken?” and “What can I do about the current situation?”“Between stimulus and response there is a space.In that space is our power to choose our response.In our response lies our growth and our freedom.”-UnknownAs scientists and engineers, we tend to be pragmatic, at least in the practice of our craft. However, staying away from judgements and evaluation of intentions of others and of ourselves can be tricky. Developing a pragmatic language of observations, and abstaining from judging intentions or pretending we are mind readers can help a lot.We know we are emitting a judgment when we give implicit intention to the subject in our sentence. For example:- “My teenage daughter is disrespectful to adults.”- “Joey ridiculed me in front of our boss at this morning’s stand-up”We can choose to stay away from judgements and evaluation by candidly sticking to observations. Observations are often expressed as gaps between what we observe and what we expected. Here are a few examples from Marshall Rosenberg’s Nonviolent Communication²:Evaluation: “The boss is procrastinating around this decision.”Observation: “The boss told us she would announce the decision by last week, but we still haven’t heard.”Evaluation: “You lied to me about your grades.”Observation: “I heard you say you passed all courses, but this report shows two F’s.”Note that both these examples imply a negative moral judgement, or an assumption of negative intent on the other party.We should also be aware that construct such as “he/she thinks that”, are assertions that imply mind reading. It is another form of evaluation that steers us away from facts and reality. For example:- “My boss thinks I don’t care about the project.”- “My husband believes I don’t love him.”Now, let’s go back to the judgment:- “Joey ridiculed me in front of our boss at this morning’s stand-up.”The first story that comes to mind might be:- “Joey wants to get a promotion and therefore he made fun of me at the stand-up to assert his dominance in front of our boss.”It is easy to spot a villain and victim story here. This is a good signal to prompt the following question:- “Can I think of something else that would explain Joey’s behavior without making him a villain or me a victim?”By doing so and pausing time between stimulus and response, we might end up with other stories such as:- “Joey saw our boss was uncomfortable and wanted to crack a joke. He wanted to re-establish safety in the conversation for him. He also fully expected me to be witty and come back at him to further diffuse the tension in the room. It was nothing personal.”We have no real way to fully assess someone else’s intentions. What we can do is choosing the stories we tell ourselves and own the space between stimulus and response.Dear reader, if you are interested in reading more, you can head to part 2.Thank you for taking the time to read this article. I am grateful for your time and consideration. I will cherish the gift of feedback, and would appreciate if you could tell me in the comments: The one concept that most resonated with you Any suggestions you may have to improve the content or the deliveryThank you! 🙏1: Stephen R Covey, The 7 Habits of Highly Effective People Habit #5: Seek first to understand, then to be understood.↩2: Marshall Rosenberg, Nonviolent Communication: A Language of Life ↩" }, { "title": "Post-mortems intro", "url": "/posts/post-mortems-intro/", "categories": "", "tags": "", "date": "2022-02-01 21:33:00 -0600", "snippet": "BackgroundIn the past, one of the Beyond engineering core values was “We Ship It!” More recently, we translated it to “Ship Early.” At Beyond, the best way to ship safely is to ship often, and the best way to ship often is to ship smaller.Shipping early is a good way to get feedback, to quickly iterate and improve on code, break wrong assumptions, rearrange logic and fix unexpected (hopefully) small errors…We work towards perfection, but we realistically know we will never be 100% perfect, not all the time. Releases do not always follow the happy path; something unexpected may happen and then we honor the other Beyond engineering principle, “We Take Ownership.” We jump into action and quickly revert or fix those errors.“What went wrong, and how/what do we learn from it?”If we take notes during the “fixing process,” from the time we found out something was wrong and what we have done to make it right, we can build a post-mortem!The concept of “post-mortem” originates from medical jargon. By definition “it is a surgical examination of a dead body in order to find out the cause of death.” This analogy can be transcribed to the engineering field as a detailed examination of an incident after it has happened. It is a useful tool to describe major incidents for the rest of the team to have a clearer picture of what went wrong and what was done to fix it!Post-mortems are intended to help us learn from past incidents and mistakes to avoid repeating them in the future.The value of post-mortems fits perfectly with Beyond’s culture since we advocate for everyone’s continuous improvement! We embrace our mistakes and learn from them!Other companies like Google, Facebook, Amazon, and Github have also adopted this type of documentation. Here you can find a github repository with an extensive list of post-mortems from those companies.What are post-mortems and why are they valuable for Beyond?As Beyond founder and CTO David Kelso once said: “It’s never fun when mistakes (…) happen, but what really matters is how we handle them.” At Beyond we do not point fingers, we do not blame people if they make mistakes, because in the end we all are humans and humans are very error prone!While someone is fixing a bigger issue, they are 100% focused on putting things back on the right track as soon as possible. They cannot (and should not) be wasting time and mental energy thinking about optimization or performing a deep dive on what caused the incident, we just want to get everything right very quickly! A good practice we tend to follow here, is to take notes during the problem solving because this will help to build great post-mortems that will be essential to provide an opportunity to reflect once the issue is no longer impacting users.Without a post-mortem, we may fail to recognize what we were doing right, where we could improve, and most importantly, how to avoid making the same mistakes in the future and come up with action items for a better long term solution.Still we need to emphasize that post-mortems are optional at our company. They are internal only, more targeted to engineering, but can also be really helpful for other departments like support and customer success managers to understand what happened and to help them polish their public messaging to our affected customers.“It’s never fun when mistakes (…) happen, but what really matters is how we handle them.” - David KelsoBasic Structure of a Post-mortemThese are all the areas that we explore with a post-mortem at Beyond: Overview - should be a super short 1 or 2 sentence description with quick reference to timeline, what happened and impact - consider this a “TLDR” section Background - If applicable, add any required background or context that is worth sharing for understanding the big picture of the problem What happened - Which servers/applications were affected? If any of the measures we took to solve the problem make it worse, we should describe them here also. Root Causes - Description of root cause for the Incident. It can be a superficial description if we are still not sure about root causes, or an in depth explanation if we are certain about the root causes. Mitigation - Basically answer the questions: “What was done to fix the issue?” and “How long did it take?” Impact - This is really a very important analytical section to show the damages and the impact on the business, for example: number of users/listings affected, syncs failed, if it was a billing related issue show values breakdown, etc. We can link third party media here, like a mode report or screenshot of datadog charts, logs, etc. Responders - Name of the people who were involved with fixing the issue Timeline - From start to finish, we can detail actions attached with the time they were taken. Try to focus on the most important facts that happened; no need to have all the little details, but if you have them, you can be as specific as just putting a date or a date and a time. Good-jobs and Improvement Chances - Answer the questions: “What did we do well?” and “Where’s the chance to improve?” Action Items - if a quick fix was applied, try to propose and follow up with a more structured long term optimized solution.How to write a Post-mortem?Humble advice on how to write a (fairly good) post-mortem: Once you detect that there is a problem, keep calm… and start to take notes! (Of course you can just rush to make everything right fast but have small bullet points of what you have done to make things correct again, writing them down will help to build the post-mortem once the problem is fixed with peace of mind) Do not forget to populate the incident timeline with the most important changes in status and key actions taken by responders. Analyze the incident: describe superficial or in depth causes as much as you can… Tell which systems/servers were affected, was it a front or backend issue? DB? etc.. For the impact part: it is nice to include charts or any other type of metric or some third-party page where the data came from. Bonus: if you can prove or illustrate that the “recovery” was successful. Create Jira tickets that may result from action items for a better long term solution. Write full body text, polish the messaging, and ask for a review from one of your colleagues or from your manager. Share the post-mortem. Sharing is caring! You should not feel shame - share with your teammates so we can all learn from mistakes to avoid them in the future!!!" } ]
